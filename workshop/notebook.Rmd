---
title: "GCA Workshop Notes"
output:
  html_document:
    fig_height: 4
    fig_width: 5
    toc: yes
---

_This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>._

These are notes and example code from a Workshop on Growth Curve Analysis with Dan Mirman at UW-Madison on June 19-20, 2014.

## Preliminaries

What are time course data? Observations from different points in time are nested within subjects.

Some challenges of analyzing time course data: 

* Two growth curves (e.g., from different experimental conditions) can be significantly different, but traditional t-tests won't detect this gradual changes over time.
* Unpredicted crossover effects where one growth curve reliably crosses over another curve. You want to avoid hand-selecting where the crossover might occur. GCA lets you look at the whole curve.

```{r, message=FALSE, warning=FALSE}
# Prepare for GCA
library("ggplot2")
library("lme4")
library("plyr")
library("reshape2")
library("multcomp")
options(width = 85)
```

## Plotting with ggplot2 

```{r}
# Lines and points
ggplot(Orange, aes(x = age, y = circumference, color = Tree)) + 
  geom_point() + geom_line()
# Black and white version
ggplot(Orange, aes(x = age, y = circumference, shape = Tree, linetype = Tree)) + 
  geom_point() + geom_line()
# Compute summary on-the-fly
ggplot(Orange, aes(age, circumference)) + 
  stat_summary(fun.y = mean, geom = "line") 
# Modify last plot
last_plot() + geom_point()
# Exclude cases on-the-fly
ggplot(subset(Orange, Tree != "5"), aes(age, circumference)) + 
  stat_summary(fun.y = mean, geom = "line") + geom_point()
# other summary statistics
ggplot(Orange, aes(age, circumference)) + 
  stat_summary(fun.data = mean_se, geom = "pointrange")
# show distribution information
ggplot(Orange, aes(factor(age), circumference)) + geom_boxplot()
ggplot(Orange, aes(factor(age), circumference)) + geom_violin()
# customizing graphs for publication
ggplot(Orange, aes(age, circumference)) + 
  stat_summary(fun.data = mean_se, geom = "pointrange") + 
  theme_bw(base_size = 12) + labs(x = "Age in days", y = "Size")
# "small multiples", aka facets
ggplot(Orange, aes(age, circumference)) + 
  facet_wrap(~ Tree) + geom_line()
ggplot(Orange, aes(age, circumference)) + 
  facet_wrap(~ Tree, ncol = 1) + geom_line()
```


## Formatting data for plotting and GCA

Example dataset: How negative affect is influenced by different 9-minute film exerpts (from `psych` package).

```{r}
load("Affect.Rdata")
summary(affect.subset)
head(affect.subset)


```

This is "wide" data; there are multiple observations in a row of data. We convert to "long" data using `melt`. Long data has one observation per row.

```{r}
# add a subject number
affect.subset$SubjNum <- seq_len(nrow(affect.subset))
affect.m <- melt(affect.subset, id.vars = c("SubjNum", "Study", "Film"), 
                 measure.vars = c("NA1", "NA2"))
summary(affect.m)
# default variable names are not very informative, customize them:
affect.m <- melt(affect.subset, measure.vars = c("NA1", "NA2"), 
                 variable.name = "TestTime", value.name = "NegAffect")
summary(affect.m)
```

Now we can use ggplot2.

```{r}
ggplot(affect.m, aes(Film, NegAffect, fill=TestTime)) + geom_boxplot()
```

`dcast` function converts a molten (`melt`-ed) data-frame from long to wide format. Useful for aggregating data and making summary tables. 

```{r}
dcast(affect.m, Film ~ TestTime, value.var = "NegAffect", fun.aggregate = mean)
```

## Conceptual overview of GCA

Observed value y is the predicted value b0 + b1X (from the fixed effects) plus the error. In multilevel data, there are multiple observations for a subject. Each subject has a level-1 regression model. The level-2 regression model estimates the level-1 regression parameters (each subject's intercepts and slopes.

### Fixed versus random effects

Fixed effects are the things that are interesting and reproducible properties of the world. As Mirman says on [his blog](http://mindingthebrain.blogspot.com/2012/08/treating-participants-or-items-as.html): 

> **Fixed effects** are the effects that we imagine to be constant in the population or group under study. As such, when we conduct a study, we would like to conclude that the observed fixed effects generalize to the whole population. So if I've run a word recognition study and found that uncommon (low frequency) words are processed slower than common (high frequency) words, I would like to conclude that this difference is true of all typical adults (or at least WEIRD adults: Henrich, Heine, & Norenzayan, 2010).

> **Random effects** are the differences among the individual observational units in the sample, which we imagine are randomly sampled from the population. As such, these effects should conform to a specified distribution (typically a normal distribution) and have a mean of 0. So in my word recognition experiment, some participants showed large a word frequency effect and some showed a small effect, but I am going to assume that these differences reflect random, normally-distributed variability in the population.

> Statistically, the difference is that fixed effect parameters are estimated independently and not constrained by a distribution. So, in the example, estimated recognition time for low and high frequency conditions can have whatever values best describe the data. Random effects are constrained to have a mean of 0 and follow a normal distribution, so estimated recognition time for a particular participant (or item, in a by-items analysis) reflects the recognition time for that individual as well as the pattern of recognition times across all other individuals in the sample. The consequence is that random effect estimates tend to be pulled toward their mean, which is called "shrinkage". So the trade-off is between independent estimation (fixed effects) and generalization (random effects).

### Maximum likelihood estimation

This is not error minimization (i.e., least squares estimation). There is not a closed-form solution for multilevel data. The modeling processing has to iteratively find the set of parameter estimates that maximizes the likelihood of the data. You compare models on the basis of likelihood comparison tests.



## Simple linear GCA example

Look at the visual search data.

```{r}
load("Examples.Rdata")
summary(VisualSearchEx)
ggplot(VisualSearchEx, aes(Set.Size, RT, color = Dx)) + 
  stat_summary(fun.data = mean_se, geom = "pointrange")
```

```{r}
# fit a base model
vs.null <- lmer(RT ~ 1 + (Set.Size | Participant), 
                data = VisualSearchEx, REML = FALSE)
# add effect of set size
vs <- lmer(RT ~ Set.Size + (Set.Size | Participant), 
           data = VisualSearchEx, REML = FALSE)
# Or:
vs <- update(vs.null, . ~ . + Set.Size)
# add effect of diagnosis
vs.0 <- update(vs.null, . ~ . + Set.Size + Dx)
# add interaction
vs.1 <- update(vs.null, . ~ . + Set.Size * Dx)
# compare models
anova(vs.null, vs, vs.0, vs.1)
```

```{r, results = 'asis'}
# Put all the model summaries together
stargazer::stargazer(vs.null, vs, vs.0, vs.1, type = "html", 
                     intercept.bottom = FALSE)
```
<br/>

Plot model fits. 

```{r}
ggplot(VisualSearchEx, aes(Set.Size, RT, color = Dx)) + 
  stat_summary(fun.data = mean_se, geom = "pointrange") + 
  stat_summary(aes(y = fitted(vs.0)), fun.y = mean, geom = "line")
# compare with full model fit
last_plot() + stat_summary(aes(y = fitted(vs.1)), fun.y = mean, 
                           geom = "line", linetype = "dashed")

```

***

## Break

```{r}
# Exercise 1: analyze the state-level suicide rate data from the WISQARS (wisqars.suicide)
#  did the regions differ in their baseline (1999) suicide rates?
#  did the regions differ in their rates of change of suidice rate?
#  plot observed data and model fits
```

***

## Non-linear GCA: Conceptual Issues

* Choosing a functional form: adequacy, dynamic consistency, predictions
* Natural and orthogonal polynomials

Dynamic consistency means that the model of the average equals the average of the models. 

Polynomials are not naturally asymptotic; they don't hit plateaus. Mirman recommends trimming off most of the tail (plateau), but do trim on a principled basis. Polynomials are not great at making predictions. Statistical models (compact data summary) are different from comptuational models (forecasting, generating data).

Natural polynomials have the unfortunate property of being correlated: e.g., `Time` and `Time^2` are correlated. Orthogonal polynomials are recentered so that they are uncorrelated.

Don't double-dip. Don't look at the overal growth curve then test for an effect in the most interesting part of the growth curve. You're interesting experimenter bias.

## Non-linear GCA example

Effect of transitional probability on word-learning.

```{r}
summary(WordLearnEx)
ggplot(WordLearnEx, aes(Block, Accuracy, color = TP)) + 
  stat_summary(fun.data = mean_se, geom = "pointrange") + 
  stat_summary(fun.y = mean, geom = "line")

# make orthogonal polynomial
t <- poly(1:10, 2)
# it can be a good idea to pull the range directly from your data set
t <- poly(1:max(WordLearnEx$Block), 2)
t
```

I wrote a function to merge polynomial times into a dataframe...

```{r}
#' Compute orthogonal times
#' @param df a data-frame
#' @param degree degree of the desired polynomial
#' @param time_col the name of the column containing the time units
#' @return a data-frame with original time values and an ot column for
#'   each polynomial degree
orthogonal_time <- function(df, degree, time_col = "Time") {
  times <- df[[time_col]]
  clean_times <- sort(unique(times))
  time_df <- as.data.frame(poly(clean_times, degree))
  names(time_df) <- paste0("ot", names(time_df))
  time_df[[time_col]] <- clean_times
  time_df
}
orthogonal_time(WordLearnEx, 2, "Block")
```


```{r}
WordLearnEx <- merge(WordLearnEx, orthogonal_time(WordLearnEx, 2, "Block"))
# re-check data
summary(WordLearnEx)
# orthogonal polynomial time
ggplot(WordLearnEx, aes(Block, ot1)) + stat_summary(fun.y=mean, geom="line")
last_plot() + stat_summary(aes(y=ot2), fun.y=mean, geom="line", color="red")

# fit base model
m.base <- lmer(Accuracy ~ (ot1+ot2) + (ot1 + ot2 | Subject), data=WordLearnEx, REML=F)
# add effect of TP on intercept 
m.0 <- update(m.base, . ~ . + TP)
# add effect on slope
m.1 <- update(m.base, . ~ . + ot1*TP)
# add effect on quadratic
m.2 <- update(m.base, . ~ . + (ot1 + ot2)*TP)

# model comparisons
anova(m.base, m.0, m.1, m.2)

# plot model fit
ggplot(WordLearnEx, aes(Block, Accuracy, color = TP)) + 
  stat_summary(fun.data = mean_se, geom = "pointrange") + 
  stat_summary(aes(y = fitted(m.2)), fun.y = mean, geom = "line")
```

### Parameter estimates

See [his blog post, "Three ways to get parameter-specific p-values from lmer"](http://mindingthebrain.blogspot.com/2014/02/three-ways-to-get-parameter-specific-p.html): 

> 1. Use the normal approximation. Since the t distribution converges to the z distribution as degrees of freedom increase, this is like assuming infinite degrees of freedom. This is unambiguously anti-conservative, but for reasonable sample sizes, it appears not to be very anti-conservative (Barr et al., 2013). That is, if we take the p-value to measure the probability of a false positive, this approximation produces a somewhat (but perhaps not alarmingly) higher false positive rate than the nominal 5% at p = 0.05.
> 2. Use the Satterthwaite approximation, which is implemented in the lmerTest package. According to the documentation, this is based on SAS proc mixed theory. The lmerTest package overloads the lmer function, so you can just re-fit the model using exactly the same code, but the summary() will now include approximate degrees of freedom and p-values. This implementation is extremely easy to use, but can be a little maddening if you forget whether your model is a an object of type lmerMod or merModLmerTest.
> 3. Use the Kenward-Roger approximation to get approximate degrees of freedom and the t-distribution to get p-values, which is implemented in the pbkrtest package.


```{r}
summary(m.2)
coefs <- data.frame(coef(summary(m.2)))
# parameter-specific p-values: use normal approximation
coefs$p <- round(2 * (1 - pnorm(abs(coefs$t.value))), 5)
coefs
```

Alternatively, use `lmerTest` to get Satterthwaite approximation. Use `lmerTest::` prefixes instead of loading the lmerTest package. This will prevent the `lmerTest` package from hijacking the commands from the `lme4` namespace.

```{r}
m.2t <- lmerTest::lmer(Accuracy ~ (ot1+ot2)*TP + (ot1+ot2 | Subject), data=WordLearnEx, REML=F)
lmerTest::summary(m.2t)
```

## More about random effects

1. WISQARS data: different random effects structures example
2. Keep it maximal
3. convergence problems can sometimes be addressed by simplifying the random effects structure
    1. remove higher-order terms
    2. remove correlations
    3. comparing model fits can help decide which random effects are least important

```{r}
# Adjust year so 1999 is Time 0 
wisqars.suicide$Year2 <- wisqars.suicide$Year - 1999
m1 <- lmer(Crude.Rate ~ Year2 + (1 | State), wisqars.suicide)
m2 <- lmer(Crude.Rate ~ Year2 + (Year2 | State), wisqars.suicide)
summary(m1)
summary(m2)
```

The standard error of the `Year2` fixed effect dramatically decreased in the second model because we allowed the `Year2` to vary randomly across states.

```{r}
qplot(data = wisqars.suicide, x = Year, y = Crude.Rate, group = State) + 
  stat_smooth(method = "lm", se = FALSE)
```

We can de-correlate random effects. This is not recommended for longitudinal data, because baseline level will be correlated rate of growth.

```{r}
# Decorrelated random effects
m3 <- lmer(Crude.Rate ~ Year2 + (1 | State) + (0 + Year2 | State), wisqars.suicide)
summary(m3)
```




## Within subject effects

Example: Target fixation in spoken word-to-picure matching (VWP)

```{r}
# plot data
ggplot(TargetFix, aes(Time, meanFix, color = Condition)) +
  stat_summary(fun.y = mean, geom = "line") +
  stat_summary(aes(fill = Condition), fun.data = mean_se, 
               geom = "ribbon", color = NA, alpha = 0.3) +
  theme_bw(base_size = 10) + expand_limits(y = c(0, 1)) + 
  labs(y = "Fixation Proportion", x = "Time since word onset (ms)")

# make 3rd-order orthogonal polynomial
TargetFix <- merge(TargetFix, orthogonal_time(TargetFix, 3, "timeBin"))

# fit full model
m.full <- lmer(meanFix ~ (ot1 + ot2 + ot3)*Condition +
              (ot1 + ot2 + ot3 | Subject) + 
              (ot1 + ot2 + ot3 | Subject:Condition),
              data = TargetFix, REML = FALSE)
summary(m.full)
# look at random effects
str(ranef(m.full))
head(ranef(m.full)$"Subject")
head(ranef(m.full)$"Subject:Condition")
VarCorr(m.full)

```

What is being estimated?

1. random variance and covariance
2. unit-level random effects

This is why df for parameter estimates are poorly defined in multilevel regression.

The object to the left of the pipe is the observation unit, so the random effects in the last model say that the observation units are `Subject` and `Subject:Condition`.

```{r}
# alternative random effect structure
m.alt <- lmer(meanFix ~ (ot1 + ot2 + ot3)*Condition + 
              ((ot1 + ot2 + ot3)*Condition | Subject), 
              data = TargetFix, REML = FALSE)
str(ranef(m.alt))
head(ranef(m.alt)$"Subject")
VarCorr(m.alt)

```

Sidenote: [This post](http://stats.stackexchange.com/questions/31569/questions-about-how-random-effects-are-specified-in-lmer) talks about the interpretation of ` | a:b` random effect terms.

This alternative version makes fewer assumptions: 

1. unequal variances across conditions
2. more flexible covariance structure between random effect terms

But it requires more parameters.

## Participants as fixed vs. random effects

Treating participants as fixed effects produces more flexible model, perhaps too flexible:

* Shrinkage
* Generalization

```{r}
m.pfix <- lmer(meanFix ~ (ot1 + ot2 + ot3)*Condition + 
                 (ot1 + ot2 + ot3)*Subject +
                 (ot1 + ot2 + ot3 | Subject:Condition), 
               data = TargetFix, REML = FALSE)
# fixed effects
coef(summary(m.pfix))
# compare with participants as random effects
coef(summary(m.full))
# compare model fits, though these models are not nested
anova(m.pfix, m.full)
```

Bottom line: Treating participants as random effects captures the typical assumption of random sampling from some population to which we wish to generalize. Treating participants as fixed effects can be appropriate when this is not the case (e.g., neurological case studies).

## Exercise 2

```{r}
# Exercise 2: Categorical perception (CP: d' peak at category boundary)
#  compare categorical perception along spectral vs. temporal dimensions using second-order orthogonal polynomial
#  which terms show significant effects of dimension type? (model comparisons)
#  estimate parameter-specific p-values using normal approximation and Satterthwaite approximation (lmerTest): to what extent do model comparisons and the two parameter-specific approaches yield the same results?
#  plot observed and model fit data

```


## Exercise 3

```{r}
# Exercise 3: analyze the combined effects of task difficulty and impairment (alcohol) on motor learning (MotorLearning)
#  plot the observed data
#  run a basic GCA with third-order orthogonal polynomials
#  re-code variables to get main effects instead of simple effects (i.e., set factor contrasts to "sum")
#  re-run GCA and compare results
```


*** 

```{r}
sessionInfo()
```
